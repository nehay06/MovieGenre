{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "from skimage import feature\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoments(image):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image: input image\n",
    "    :return: numpy array which contains the mean,standard deviation,skewness and heuMoments of the image\n",
    "    \"\"\"\n",
    "\n",
    "    #read the image in HSV color space\n",
    "    imageHSV = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #calculate the mean and standard deviation of the image\n",
    "    (means, stds) = cv2.meanStdDev(imageHSV)\n",
    "\n",
    "    #calculate the image moments\n",
    "    moments = cv2.moments(imageHSV[:,:,0])\n",
    "    skew0 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    moments = cv2.moments(imageHSV[:,:,1])\n",
    "    skew1 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    moments = cv2.moments(imageHSV[:,:,2])\n",
    "    skew2 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    skew = np.asarray([skew0,skew1,skew2]).reshape((3, 1))\n",
    "\n",
    "    #concatenate the mean,standard deviation,skew features into a single numpy array\n",
    "    stats = np.concatenate([means, stds,skew]).flatten()\n",
    "\n",
    "    #calculate the HuMoments of the image\n",
    "    imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    Moments = cv2.HuMoments(cv2.moments(imageGray)).flatten()\n",
    "    moments = np.asarray(Moments)\n",
    "\n",
    "    #form the final feature vector which contains the mean,standard deviation, skewness and HueMoments of the image\n",
    "    finalFeatureVector = np.append(stats,moments)\n",
    "\n",
    "    #return the feature vector\n",
    "    return finalFeatureVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTopHSVFeatures(image,bins):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "    chans = cv2.split(image)\n",
    "    features = []\n",
    "#     for ind,channel in enumerate(chans):\n",
    "#         print ind\n",
    "#         if ind == 0:\n",
    "#             hist = cv2.calcHist([channel], [0], None, [180], [0, 180]) \n",
    "#         else:\n",
    "#             hist = cv2.calcHist([channel], [0], None, [256], [0, 256]) \n",
    "#         histFeatures = cv2.normalize(hist,hist).flatten()\n",
    "#         temp = np.partition(-histFeatures, 48)\n",
    "#         result = -temp[:36]\n",
    "#         features.extend(histFeatures)\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "    histFeatures = cv2.normalize(hist,hist).flatten()\n",
    "    temp = np.partition(-histFeatures, 48)\n",
    "    result = -temp[:48]\n",
    "    features.extend(result)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHSVFeatures(image,bins):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "    features = cv2.normalize(hist,hist).flatten()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refinedHSVFeatures(image,bins):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    features = []\n",
    "    \n",
    "    #compute the center of the move image poster.\n",
    "    (height, width) = image.shape[:2]\n",
    "    (centerX, centerY) = (int(width * 0.5), int(height * 0.5))\n",
    "    \n",
    "    #entire image is segmented into four rectangeles i.e top-left,top-right, bottom-left, bottom-right\n",
    "    Imagesegments = [(0, centerX, 0, centerY), (centerX, width, 0, centerY), (centerX, width, centerY, height),\n",
    "            (0, centerX, centerY, height)]\n",
    "    \n",
    "    #an elliptal mask covering the center of the image is created, this will be used to compute the histogram of\n",
    "    #5 region i.e the mask will be substracted from 5 rectangular regions created above\n",
    "\n",
    "    (axesX, axesY) = (int(width * 0.75) / 2, int(height * 0.75) / 2)\n",
    "    ellipMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "    cv2.ellipse(ellipMask, (centerX, centerY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
    "    \n",
    "    # loop over the created rectange image segements \n",
    "    for (startX, endX, startY, endY) in Imagesegments:\n",
    "        # a mask is created for each corner of the image by sustracting the elliptical mask created above\n",
    "        cornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "        cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
    "        cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
    "\n",
    "        # color histogram from each sub region of the image is computed and then feature vector is updated accordingly.\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], cornerMask, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "        hist = cv2.normalize(hist,hist).flatten()\n",
    "        features.extend(hist)\n",
    "\n",
    "    #at last the color histogram from the elliptical region of the image is computer and \n",
    "    # feature vector is updated accordingle.\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], ellipMask, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist,hist).flatten()\n",
    "    features.extend(hist)\n",
    "    \n",
    "    # return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file into panda dataframe. The column names description:\n",
    "\n",
    "**Genre** : Genre for the given File\n",
    "\n",
    "**imdbId**: Image file name (File names are the imdbID for the given movie)\n",
    "\n",
    "**Feature1**: Label assigned to image file with given Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action|Adventure|Drama</td>\n",
       "      <td>35153</td>\n",
       "      <td>Action</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama</td>\n",
       "      <td>1630036</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1195478</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Action|Crime</td>\n",
       "      <td>79966</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama|History</td>\n",
       "      <td>1029364</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Genre   imdbId Feature1  Feature2\n",
       "0  Action|Adventure|Drama    35153   Action         0\n",
       "1                   Drama  1630036    Drama         1\n",
       "2          Comedy|Romance  1195478   Comedy         2\n",
       "3     Comedy|Action|Crime    79966   Comedy         2\n",
       "4           Drama|History  1029364    Drama         1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../Dataset/Top3FullGenre.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the columns of the dataframe. This contains the columns of data contained in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1', 'Feature2']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the count of each Genre category in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama                       4205\n",
       "Comedy                      2408\n",
       "Comedy|Drama                1474\n",
       "Drama|Romance               1448\n",
       "Comedy|Drama|Romance        1130\n",
       "Comedy|Romance              1002\n",
       "Action|Crime|Drama           558\n",
       "Drama|Thriller               509\n",
       "Drama|War                    321\n",
       "Comedy|Crime|Drama           289\n",
       "Action|Comedy|Crime          275\n",
       "Action|Adventure|Drama       264\n",
       "Action|Crime|Thriller        256\n",
       "Comedy|Crime                 247\n",
       "Action|Adventure|Comedy      245\n",
       "Drama|Mystery|Thriller       199\n",
       "Comedy|Horror                194\n",
       "Action|Drama                 183\n",
       "Comedy|Drama|Family          169\n",
       "Action|Thriller              167\n",
       "Drama|History                166\n",
       "Action|Drama|Thriller        164\n",
       "Action|Adventure|Sci-Fi      163\n",
       "Comedy|Drama|Music           147\n",
       "Drama|Horror|Thriller        141\n",
       "Action|Adventure|Fantasy     137\n",
       "Comedy|Musical|Romance       136\n",
       "Drama|Horror|Mystery         135\n",
       "Drama|Family                 134\n",
       "Action                       131\n",
       "                            ... \n",
       "Action|Fantasy|History         1\n",
       "Drama|Fantasy|Family           1\n",
       "Drama|Documentary|Music        1\n",
       "Drama|Horror|Fantasy           1\n",
       "Comedy|Romance|Adventure       1\n",
       "Action|Comedy|Animation        1\n",
       "Action|War|Western             1\n",
       "Drama|Sci-Fi|Crime             1\n",
       "Drama|Mystery|Music            1\n",
       "Drama|Family|Mystery           1\n",
       "Action|Western|Adventure       1\n",
       "Comedy|History|Music           1\n",
       "Comedy|Action|Family           1\n",
       "Drama|Fantasy|Sport            1\n",
       "Drama|Sci-Fi|Romance           1\n",
       "Action|Musical|Mystery         1\n",
       "Drama|Mystery|News             1\n",
       "Drama|Sci-Fi|Horror            1\n",
       "Drama|Short|Fantasy            1\n",
       "Comedy|Fantasy|Drama           1\n",
       "Drama|Sport|Western            1\n",
       "Drama|Musical|Sport            1\n",
       "Comedy|Documentary|Drama       1\n",
       "Drama|Music|Sport              1\n",
       "Drama|Comedy|Family            1\n",
       "Action|Horror|Western          1\n",
       "Comedy|War|Fantasy             1\n",
       "Comedy|Family|War              1\n",
       "Drama|War|Comedy               1\n",
       "Comedy|Action|Thriller         1\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the unique Genre present in data and their count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Genre.unique()\n",
    "print (uniqueGenre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadHSVFeatures():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = getHSVFeatures(original_image,(8, 24, 3))    \n",
    "        inputData.append(features)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTopHSVFeatures():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = getTopHSVFeatures(original_image,(8, 24, 3))    \n",
    "        inputData.append(features)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadMomentFeatures():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = getMoments(original_image)\n",
    "        inputData.append(features)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadRefinedHSVFeatures():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = refinedHSVFeatures(original_image,(8, 12, 3))    \n",
    "        inputData.append(features)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadTopHSVMomentFeatures():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = getTopHSVFeatures(original_image,(8, 24, 3))\n",
    "        moments = getMoments(original_image)\n",
    "        inputData.append(np.append(features,moments))\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadHSVMomentFeatures():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = getHSVFeatures(original_image,(8, 24, 3))\n",
    "        moments = getMoments(original_image)\n",
    "        inputData.append(np.append(features,moments))\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((13800, 576), (13800,))\n"
     ]
    }
   ],
   "source": [
    "HSVFeatures,HSVLabels = loadHSVFeatures()\n",
    "HSVFeatures,HSVLabels = np.asarray(HSVFeatures),np.asarray(HSVLabels)\n",
    "print (HSVFeatures.shape,HSVLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((13800, 1440), (13800,))\n"
     ]
    }
   ],
   "source": [
    "RefinedHSVFeatures,Labels = loadRefinedHSVFeatures()\n",
    "RefinedHSVFeatures,Labels = np.asarray(RefinedHSVFeatures),np.asarray(Labels)\n",
    "print (RefinedHSVFeatures.shape,Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8172, 16), (8172,))\n"
     ]
    }
   ],
   "source": [
    "MomentFeatues,MomentLabels = loadMomentFeatures()\n",
    "MomentFeatues,MomentLabels = np.asarray(MomentFeatues),np.asarray(MomentLabels)\n",
    "print (MomentFeatues.shape,MomentLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24161, 592) (24161,)\n"
     ]
    }
   ],
   "source": [
    "cFeatures,cLabels = LoadHSVMomentFeatures()\n",
    "cFeatures,cLabels = np.asarray(cFeatures),np.asarray(cLabels)\n",
    "print (cFeatures.shape,cLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combinedFeatures,combinedLabels = loadTopHSVMomentFeatures()\n",
    "combinedFeatures,combinedLabels = np.asarray(combinedFeatures),np.asarray(combinedLabels)\n",
    "print (combinedFeatures.shape,combinedLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TopHSVFeatures,Labels = loadTopHSVFeatures()\n",
    "TopHSVFeatures,Labels = np.asarray(TopHSVFeatures),np.asarray(Labels)\n",
    "print (TopHSVFeatures.shape,Labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into training data and testing data using sklearn train_test_split. The following is the definition of:\n",
    "\n",
    "**X_train**: This is a numpy array of feature vectors of the image for train the classifier.\n",
    "\n",
    "**X_test**:This is numpy array of lables of the images for training the classifier.\n",
    "\n",
    "**y_train**: This is a numpy array of feature vectors of the image for testing the classifier.\n",
    "\n",
    "**y_test** This is numpy array of lables of the images for testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18120, 592) (6041, 592) (18120,) (6041,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cFeatures, cLabels, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,chi2,SelectPercentile,SelectFpr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForestClassifier classifier and perform cross validation using GridSearchCV and feature selection using recursive cross validation. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search to tune the hyper parameters of the model\n",
      "Performing Pipeline Steps: ['clf']\n",
      "parameters are :\n",
      "{'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'clf__n_estimators': [10, 20, 50, 100],\n",
      " 'clf__random_state': [300, 400, 700]}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed: 17.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the classifier is 1103.87059689\n",
      "\n",
      "Best score 0.551876379691\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'log2'\n",
      "\tclf__n_estimators: 100\n",
      "\tclf__random_state: 700\n",
      "Time to test the classifier is 1.82891011238\n",
      "Calculated Accuracy is 0.555206091707\n",
      "Precision Score is 0.555168510035\n",
      "Recall Score is 0.555206091707\n",
      "F1 Score is 0.533445641052\n",
      "confusion matrix:\n",
      "[[ 219  410  579]\n",
      " [  80 1571  754]\n",
      " [  97  767 1564]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel='linear'),scoring='accuracy',cv=StratifiedKFold(),step=1)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [10,20,50,100],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__random_state':[300,400,700]\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "RandomForestModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing Pipeline Steps:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "RandomForestModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score {}\".format(RandomForestModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = RandomForestModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = RandomForestModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time() - t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier: \n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Time to train the model is 10.706553936\n",
      "Time to test the model is 0.0874669551849\n",
      "confusion matrix:\n",
      "[[205  99  77]\n",
      " [134 152  97]\n",
      " [ 81  60 220]]\n",
      "Calculated Accuracy is 0.512888888889\n",
      "Precision Score is 0.510868978121\n",
      "Recall Score is 0.512888888889\n",
      "F1 Score is 0.509486475557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "print(\"Training the classifier: \")\n",
    "print(clf)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Time to test the model is {}\".format(time() - t0))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "     ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', AdaBoostClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50,70,90],\n",
    "    'clf__random_state': [1,20,40]\n",
    "}\n",
    "AdaBoostModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "AdaBoostModel.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Best reported score is {}\".format(AdaBoostModel.best_score_))\n",
    "print(\"Best parameters set are: \"))\n",
    "best_parameters = AdaBoostModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {} \".format(param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = AdaBoostModel.predict(X_test)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "print(\"Training the classifier...\")\n",
    "t0 = time()\n",
    "param_grid = {'hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "              'activation' :['logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'alpha':[ 0.0001, 0.001, 0.01]}\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid)\n",
    "print(clf)\n",
    "X_train = SelectKBest(chi2, k=2).fit_transform(X_train, y_train)\n",
    "X_test = SelectKBest(chi2, k=2).fit_transform(X_test, y_test)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search to tune the hyper parameters of the model\n",
      "pipeline : ['clf']\n",
      "parameters are :\n",
      "{'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
      " 'clf__alpha': [0.0001, 0.001, 0.001],\n",
      " 'clf__hidden_layer_sizes': [(70, 20, 10), (40, 20, 10), (90, 20, 10)],\n",
      " 'clf__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
      " 'clf__solver': ['lbfgs', 'sgd', 'adam']}\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 13.6min\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 34.5min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 62.8min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed: 75.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the classifier is 4526.29595399\n",
      "\n",
      "Best score:0.485333333333\n",
      "Best parameters set:\n",
      "\tclf__activation: 'logistic'\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__hidden_layer_sizes: (90, 20, 10)\n",
      "\tclf__learning_rate: 'constant'\n",
      "\tclf__solver: 'adam'\n",
      "Time to test the classifier is 0.0880341529846\n",
      "Calculated Accuracy is 0.497777777778\n",
      "Precision Score is 0.490777728344\n",
      "Recall Score is 0.497777777778\n",
      "F1 Score is 0.473092479685\n",
      "confusion matrix:\n",
      "[[205  99  77]\n",
      " [134 152  97]\n",
      " [ 81  60 220]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "    #('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'clf__solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'clf__alpha':[ 0.0001, 0.001, 0.001],\n",
    "    'clf__learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "\n",
    "MLPModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "MLPModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time()-t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( MLPModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = MLPModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = MLPModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time()-t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Scores using VotingClassifier. The classifiers used are LogisticRegression(),KNeighborsClassifier() and  MLPClassifier().  Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = MLPClassifier()\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3)], voting='hard')\n",
    "print(\"Training the classifier...\")\n",
    "print(eclf1)\n",
    "t0 = time()\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = eclf1.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "print(\"The confusion matrix: {}\".format(metrics.confusion_matrix(y_test, pred)))\n",
    "print(\"Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train linear SVM  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline Parameters: ['clf']\n",
      "Chosen Parameters: are\n",
      "{'clf__C': (0.001, 0.0001, 0.01, 1),\n",
      " 'clf__kernel': ('linear', 'rbf', 'sigmoid', 'poly')}\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    #('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly'),\n",
    "    'clf__C': (0.001,0.0001,0.01,1)\n",
    "}\n",
    "SVC_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( SVC_clf.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVC by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search to tune the hyper parameters of the model\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {\n",
    "    'C': (0.001,0.0001,0.01,1)\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "SVC_clf = GridSearchCV(SVC(kernel=\"linear\"), parameters, n_jobs=-1, verbose=1)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\" \")\n",
    "print(\"Best score: %0.3f\" % SVC_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
