{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "from skimage import feature\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file into panda dataframe. The column names description:\n",
    "\n",
    "**Genre** : Genre for the given File\n",
    "\n",
    "**imdbId**: Image file name (File names are the imdbID for the given movie)\n",
    "\n",
    "**Feature1**: Label assigned to image file with given Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>113101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama</td>\n",
       "      <td>114117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drama</td>\n",
       "      <td>110299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>115683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama</td>\n",
       "      <td>114753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Genre  imdbId  Feature1\n",
       "0  Comedy  113101         0\n",
       "1   Drama  114117         1\n",
       "2   Drama  110299         1\n",
       "3  Comedy  115683         0\n",
       "4   Drama  114753         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../Dataset/Genres3Labels.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the columns of the dataframe. This contains the columns of data contained in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the count of each Genre category in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama          4205\n",
       "Comedy         2408\n",
       "Documentary    1559\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the unique Genre present in data and their count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Feature1.unique()\n",
    "print(uniqueGenre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the sift featurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSIFTFeatures(image):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBOWTrain():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    bow_train = cv2.BOWKMeansTrainer(100)\n",
    "    detect = cv2.xfeatures2d.SIFT_create()\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename,0)\n",
    "        keypoints, descriptors = getSIFTFeatures(original_image)\n",
    "        bow_train.add(descriptors)\n",
    "    return bow_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_train = getBOWTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadBOWFeatures(bow_train):\n",
    "    \"\"\"\n",
    "\n",
    "    :param bow_train: This contains the SIFT features descriptors added to BOWKMeansTrainer\n",
    "    :return: feature descriptors and labels\n",
    "    \"\"\"\n",
    "    flann_params = dict(algorithm = 1, trees = 5)\n",
    "    matcher = cv2.FlannBasedMatcher(flann_params, dict(checks=50))\n",
    "    voc = bow_train.cluster()\n",
    "    extract = cv2.xfeatures2d.SIFT_create()\n",
    "    detect = cv2.xfeatures2d.SIFT_create()\n",
    "    bow_extract = cv2.BOWImgDescriptorExtractor( extract, cv2.BFMatcher(cv2.NORM_L2) )\n",
    "    bow_extract.setVocabulary( voc )\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"\n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image =cv2.imread(imageDir+filename,0)\n",
    "        bowFeatures = bow_extract.compute(original_image, detect.detect(original_image))\n",
    "        inputData.extend(bowFeatures)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "BOWFeatures,BOWLabels = loadBOWFeatures(bow_train)\n",
    "test_time = time() - t0\n",
    "print(\"Feature Extraction time:  %0.3fs\" % test_time)\n",
    "BOWFeatures,BOWLabels = np.asarray(BOWFeatures),np.asarray(BOWLabels)\n",
    "print (BOWFeatures.shape , BOWLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into training data and testing data using sklearn train_test_split. The following is the definition of:\n",
    "\n",
    "**X_train**: This is a numpy array of feature vectors of the image for train the classifier.\n",
    "\n",
    "**X_test**:This is numpy array of lables of the images for training the classifier.\n",
    "\n",
    "**y_train**: This is a numpy array of feature vectors of the image for testing the classifier.\n",
    "\n",
    "**y_test** This is numpy array of lables of the images for testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(BOWFeatures, BOWLabels, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,chi2,SelectPercentile,SelectFpr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForestClassifier classifier and perform cross validation using GridSearchCV and feature selection using recursive cross validation. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'clf__n_estimators': [10, 20, 50, 100],\n",
      " 'clf__random_state': [300, 400, 700]}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   59.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 62.238s\n",
      "\n",
      "Best score: 0.391\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 50\n",
      "\tclf__random_state: 700\n",
      "Calculated Accuracy is 0.360888888889\n",
      "Precision Score is 0.361624873602\n",
      "Recall Score is 0.360888888889\n",
      "F1 Score is 0.36038379701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel='linear'),scoring='accuracy',cv=StratifiedKFold(),step=1)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [10,20,50,100],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__random_state':[300,400,700]\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "RandomForestModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing Pipeline Steps:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "RandomForestModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score {}\".format(RandomForestModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = RandomForestModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = RandomForestModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time() - t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "print(\"Training the classifier: \")\n",
    "print(clf)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Time to test the model is {}\".format(time() - t0))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__n_estimators': [50, 70, 90], 'clf__random_state': [1, 20, 40]}\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   12.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 14.724s\n",
      "\n",
      "Best score: 0.408\n",
      "Best parameters set:\n",
      "\tclf__n_estimators: 90\n",
      "\tclf__random_state: 1\n",
      "confusion matrix:\n",
      "[[149  99 127]\n",
      " [113 132 163]\n",
      " [ 81 111 150]]\n",
      "Calculated Accuracy is 0.382222222222\n",
      "Precision Score is 0.388026640958\n",
      "Recall Score is 0.382222222222\n",
      "F1 Score is 0.382603326644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "     ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', AdaBoostClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50,70,90],\n",
    "    'clf__random_state': [1,20,40]\n",
    "}\n",
    "AdaBoostModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "AdaBoostModel.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Best reported score is {}\".format(AdaBoostModel.best_score_))\n",
    "print(\"Best parameters set are: \"))\n",
    "best_parameters = AdaBoostModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {} \".format(param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = AdaBoostModel.predict(X_test)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': [0.0001, 0.001, 0.01], 'activation': ['logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [(70, 20, 10), (40, 20, 10), (90, 20, 10)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "train time: 168.683s\n",
      "test time:  0.002s\n",
      "confusion matrix:\n",
      "[[127 106 142]\n",
      " [ 71 174 163]\n",
      " [ 56 132 154]]\n",
      "Calculated Accuracy is 0.404444444444\n",
      "Precision Score is 0.421827357912\n",
      "Recall Score is 0.404444444444\n",
      "F1 Score is 0.405411271197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "print(\"Training the classifier...\")\n",
    "t0 = time()\n",
    "param_grid = {'hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "              'activation' :['logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'alpha':[ 0.0001, 0.001, 0.01]}\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid)\n",
    "print(clf)\n",
    "X_train = SelectKBest(chi2, k=2).fit_transform(X_train, y_train)\n",
    "X_test = SelectKBest(chi2, k=2).fit_transform(X_test, y_test)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
      " 'clf__alpha': [0.0001, 0.001, 0.001],\n",
      " 'clf__hidden_layer_sizes': [(70, 20, 10), (40, 20, 10), (90, 20, 10)],\n",
      " 'clf__learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
      " 'clf__solver': ['lbfgs', 'sgd', 'adam']}\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.4min\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 972 out of 972 | elapsed:  8.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 526.412s\n",
      "\n",
      "Best score: 0.428\n",
      "Best parameters set:\n",
      "\tclf__activation: 'relu'\n",
      "\tclf__alpha: 0.0001\n",
      "\tclf__hidden_layer_sizes: (90, 20, 10)\n",
      "\tclf__learning_rate: 'adaptive'\n",
      "\tclf__solver: 'lbfgs'\n",
      "Calculated Accuracy is 0.386666666667\n",
      "Precision Score is 0.413962243581\n",
      "Recall Score is 0.386666666667\n",
      "F1 Score is 0.386451447169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'clf__solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'clf__alpha':[ 0.0001, 0.001, 0.001],\n",
    "    'clf__learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "\n",
    "MLPModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "MLPModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time()-t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( MLPModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = MLPModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = MLPModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time()-t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Scores using VotingClassifier. The classifiers used are LogisticRegression(),KNeighborsClassifier() and  MLPClassifier().  Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('rf', KNeighb...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))],\n",
      "         n_jobs=1, voting='hard', weights=None)\n",
      "train time: 0.650s\n",
      "test time:  0.022s\n",
      "confusion matrix:\n",
      "[[ 77 100 198]\n",
      " [ 46 169 193]\n",
      " [ 43 123 176]]\n",
      "Calculated Accuracy is 0.375111111111\n",
      "Precision Score is 0.405335531089\n",
      "Recall Score is 0.375111111111\n",
      "F1 Score is 0.365833252279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = MLPClassifier()\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3)], voting='hard')\n",
    "print(\"Training the classifier...\")\n",
    "print(eclf1)\n",
    "t0 = time()\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = eclf1.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "print(\"The confusion matrix: {}\".format(metrics.confusion_matrix(y_test, pred)))\n",
    "print(\"Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train linear SVM  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.001, 0.0001, 0.01),\n",
      " 'clf__kernel': ('linear', 'rbf', 'sigmoid', 'poly')}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.955s\n",
      "\n",
      "Best score: 0.343\n",
      "Best parameters set:\n",
      "\tclf__C: 0.001\n",
      "\tclf__kernel: 'linear'\n",
      "Calculated Accuracy is 0.304\n",
      "Precision Score is 0.092416\n",
      "Recall Score is 0.304\n",
      "F1 Score is 0.141742331288\n",
      "confusion matrix:\n",
      "[[ 77 100 198]\n",
      " [ 46 169 193]\n",
      " [ 43 123 176]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly'),\n",
    "    'clf__C': (0.001,0.0001,0.01)\n",
    "}\n",
    "SVC_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( SVC_clf.best_score)_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVC by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {\n",
    "    'C': (0.001,0.0001,0.01,1)\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "SVC_clf = GridSearchCV(SVC(kernel=\"linear\"), parameters, n_jobs=-1, verbose=1)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\" \")\n",
    "print(\"Best score: %0.3f\" % SVC_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
