{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def refinedHSVFeatures(image,bins):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    features = []\n",
    "    \n",
    "    #compute the center of the image\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
    "    # divide the image into four rectangles/segments (top-left,\n",
    "    # top-right, bottom-right, bottom-left)\n",
    "    segments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h),\n",
    "            (0, cX, cY, h)]\n",
    "    \n",
    "    # construct an elliptical mask representing the center of the\n",
    "        # image\n",
    "    (axesX, axesY) = (int(w * 0.75) / 2, int(h * 0.75) / 2)\n",
    "    ellipMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "    cv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
    "    \n",
    "    # loop over the segments\n",
    "    for (startX, endX, startY, endY) in segments:\n",
    "        # construct a mask for each corner of the image, subtracting\n",
    "        # the elliptical center from it\n",
    "        cornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "        cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
    "        cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
    "\n",
    "        # extract a color histogram from the image, then update the\n",
    "        # feature vector\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], cornerMask, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "        hist = cv2.normalize(hist,hist).flatten()\n",
    "        features.extend(hist)\n",
    "\n",
    "    # extract a color histogram from the elliptical region and\n",
    "    # update the feature vector\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], ellipMask, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "    hist = cv2.normalize(hist,hist).flatten()\n",
    "    features.extend(hist)\n",
    "    \n",
    "    # return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_var):\n",
    "    network = lasagne.layers.InputLayer(shape=(None,1,1440), input_var = input_var)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "      \n",
    "    network = lasagne.layers.DenseLayer(network, num_units = 100, nonlinearity = lasagne.nonlinearities.rectify)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "\n",
    "#     network = lasagne.layers.DenseLayer(network, num_units = 50, nonlinearity = lasagne.nonlinearities.rectify)\n",
    "#     print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(network, num_units = 5, nonlinearity = lasagne.nonlinearities.softmax)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, Y, batchsize):\n",
    "    row, col,y = X.shape\n",
    "    for i in range(int(row/batchsize)) :\n",
    "        yield X[batchsize*i: batchsize*(i+1),:], Y[batchsize*i: batchsize*(i+1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_test, Y_test):\n",
    "    input_var = T.dtensor3(\"inputs\")\n",
    "    target_var = T.lmatrix(\"targets\")\n",
    "    X_train = X_train.reshape((-1,1,1440))\n",
    "    X_test = X_test.reshape((-1,1,1440))\n",
    "    network = build_model(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    \n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    #updates = lasagne.updates.rmsprop(loss, params, learning_rate=0.01, rho=0.9, epsilon=1e-06)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    \n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), T.argmax(target_var,axis = 1)),\n",
    "                  dtype=theano.config.floatX)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    num_epochs = 18\n",
    "    \n",
    "            \n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_acc = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for i,batch in enumerate(iterate_minibatches(X_train, Y_train, 100)):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            train_acc += acc\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_test, Y_test, 100):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  training accuracy:\\t\\t{:.2f} %\".format(\n",
    "            train_acc / train_batches * 100))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>113101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama</td>\n",
       "      <td>114117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drama</td>\n",
       "      <td>110299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>115683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama</td>\n",
       "      <td>114753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Genre  imdbId  Feature1\n",
       "0  Comedy  113101         0\n",
       "1   Drama  114117         1\n",
       "2   Drama  110299         1\n",
       "3  Comedy  115683         0\n",
       "4   Drama  114753         1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../Dataset/Genres3Labels.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8172, 3)\n"
     ]
    }
   ],
   "source": [
    "df.Genre.value_counts()\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Genre.unique()\n",
    "print(uniqueGenre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import cv2\n",
    "def load_dataset():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    imageData = np.zeros((8172,1440))\n",
    "    outputData = np.zeros((8172,5),dtype=int)\n",
    "    cd = ColorDescriptor((8, 12, 3))\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = imread(imageDir+filename)\n",
    "        HSVFeatures = refinedHSVFeatures(original_image,(8, 12, 3))   \n",
    "        imageData[index,:] =np.asarray(HSVFeatures)\n",
    "        outputData[index,label] = 1\n",
    "    return imageData,outputData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((8172, 1440), (8172, 5))\n"
     ]
    }
   ],
   "source": [
    "InputFeatures,Labels = load_dataset()\n",
    "InputFeatures,Labels = np.asarray(InputFeatures),np.asarray(Labels)\n",
    "print (InputFeatures.shape,Labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6129, 1440) (2043, 1440) (6129,) (2043,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(InputFeatures, Labels, test_size=0.25, random_state=42)\n",
    "print X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 8825760 into shape (1,1474)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-b89f96914491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-73a20f7c141c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1474\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1474\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 8825760 into shape (1,1474)"
     ]
    }
   ],
   "source": [
    "network = train_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "[[ 0.40055241  0.5191358   0.02452395  0.0388191   0.01696873]\n",
      " [ 0.13544186  0.80974042  0.00760744  0.03144713  0.01576315]\n",
      " [ 0.01469123  0.86780661  0.07276419  0.02667581  0.01806215]\n",
      " ..., \n",
      " [ 0.94806216  0.03479305  0.0042972   0.00853998  0.00430761]\n",
      " [ 0.08108664  0.31693075  0.40579123  0.11753428  0.07865709]\n",
      " [ 0.00305813  0.41704027  0.54050119  0.02152758  0.01787283]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "print type(X_test)\n",
    "def testAccuracy(X_test,Y_test):\n",
    "    X_test = X_test.reshape((-1,1,1474))\n",
    "    predictedLabels = lasagne.layers.get_output(network,inputs = X_test).eval()\n",
    "    return predictedLabels\n",
    "predictedLabels = testAccuracy(X_test,y_test)\n",
    "print (predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2304, 5)\n",
      "(2304, 5)\n",
      "[[0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " ..., \n",
      " [1 0 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print predictedLabels.shape\n",
    "print y_test.shape\n",
    "Y_Pred = np.zeros(predictedLabels.shape,dtype = int)\n",
    "rows = np.argmax(predictedLabels, axis=1)\n",
    "for i in range(y_test.shape[0]):\n",
    "    Y_Pred[i,rows[i]] = 1\n",
    "print  Y_Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported Accuracy is 0.505208333333\n",
      "precision_score is 0.438481474557\n",
      "recall_score is 0.505208333333\n",
      "f1_score is 0.450673749442\n",
      "confusion matrix:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-658049e34c0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"confusion matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "Y_test = y_test\n",
    "accuracyscore = accuracy_score(Y_test, Y_Pred)\n",
    "f1score = f1_score(Y_test, Y_Pred, average='weighted') \n",
    "precisionscore = precision_score(Y_test, Y_Pred, average='weighted')\n",
    "recallscore = recall_score(Y_test, Y_Pred, average='weighted') \n",
    "print(\"Reported Accuracy is {}\".format(accuracyscore))\n",
    "print(\"precision_score is {}\".format(precisionscore))\n",
    "print(\"recall_score is {}\".format(recallscore))\n",
    "print(\"f1_score is {}\".format(f1score))\n",
    "# print(\"confusion matrix:\")\n",
    "# print(metrics.confusion_matrix(y_test, Y_Pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
