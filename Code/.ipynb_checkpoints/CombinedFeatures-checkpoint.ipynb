{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "from skimage import feature\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoments(image):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image: input image\n",
    "    :return: numpy array which contains the mean,standard deviation,skewness and heuMoments of the image\n",
    "    \"\"\"\n",
    "\n",
    "    #read the image in HSV color space\n",
    "    imageHSV = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #calculate the mean and standard deviation of the image\n",
    "    (means, stds) = cv2.meanStdDev(imageHSV)\n",
    "\n",
    "    #calculate the image moments\n",
    "    moments = cv2.moments(imageHSV[:,:,0])\n",
    "    skew0 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    moments = cv2.moments(imageHSV[:,:,1])\n",
    "    skew1 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    moments = cv2.moments(imageHSV[:,:,2])\n",
    "    skew2 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    skew = np.asarray([skew0,skew1,skew2]).reshape((3, 1))\n",
    "\n",
    "    #concatenate the mean,standard deviation,skew features into a single numpy array\n",
    "    stats = np.concatenate([means, stds,skew]).flatten()\n",
    "\n",
    "    #calculate the HuMoments of the image\n",
    "    imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    Moments = cv2.HuMoments(cv2.moments(imageGray)).flatten()\n",
    "    moments = np.asarray(Moments)\n",
    "\n",
    "    #form the final feature vector which contains the mean,standard deviation, skewness and HueMoments of the image\n",
    "    finalFeatureVector = np.append(stats,moments)\n",
    "\n",
    "    #return the feature vector\n",
    "    return finalFeatureVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getHSVFeatures(image,bins):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "    features = cv2.normalize(hist,hist).flatten()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLBPFeatures(image,numPoints, radius):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image: input image (greyscale) as numpy array\n",
    "    :param numPoints:number of points p in a circularly symmetric neighborhood of central pixel\n",
    "    :param radius: radius of the circle\n",
    "    :return: histogram of Local binary pattern of given image\n",
    "    \"\"\"\n",
    "    lbp = feature.local_binary_pattern(image, numPoints,\n",
    "            radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, numPoints + 3),\n",
    "            range=(0, numPoints + 2))\n",
    "    # normalize the histogram\n",
    "    eps=1e-7\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_Features():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename)\n",
    "        features = getHSVFeatures(original_image,(8, 12, 3))   \n",
    "        moments = getMoments(original_image)\n",
    "        cFeatures = np.append(features,moments)\n",
    "        original_image = imread(imageDir+filename,as_grey= True)\n",
    "        hist = getLBPFeatures(original_image,24,8)\n",
    "        inputData.append(np.append(cFeatures,hist))\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file into panda dataframe. The column names description:\n",
    "\n",
    "**Genre** : Genre for the given File\n",
    "\n",
    "**imdbId**: Image file name (File names are the imdbID for the given movie)\n",
    "\n",
    "**Feature1**: Label assigned to image file with given Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action|Comedy|Crime</td>\n",
       "      <td>71216</td>\n",
       "      <td>Action</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>245238</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drama|War</td>\n",
       "      <td>263366</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Family|Horror</td>\n",
       "      <td>61550</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action|Adventure|Drama</td>\n",
       "      <td>422091</td>\n",
       "      <td>Action</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Genre  imdbId Feature1  Feature2\n",
       "0     Action|Comedy|Crime   71216   Action         0\n",
       "1           Drama|Romance  245238    Drama         1\n",
       "2               Drama|War  263366    Drama         1\n",
       "3    Comedy|Family|Horror   61550   Comedy         2\n",
       "4  Action|Adventure|Drama  422091   Action         0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../Dataset/BalancedTop3FullGenre.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the columns of the dataframe. This contains the columns of data contained in .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1', 'Feature2']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the count of each Genre category in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama                        1638\n",
       "Drama|Romance                 826\n",
       "Comedy                        731\n",
       "Comedy|Drama|Romance          686\n",
       "Comedy|Drama                  676\n",
       "Action|Crime|Drama            546\n",
       "Comedy|Romance                496\n",
       "Action|Comedy|Crime           269\n",
       "Action|Adventure|Drama        256\n",
       "Action|Crime|Thriller         243\n",
       "Action|Adventure|Comedy       239\n",
       "Drama|Thriller                216\n",
       "Comedy|Crime|Drama            182\n",
       "Drama|War                     180\n",
       "Action|Drama                  180\n",
       "Action|Thriller               161\n",
       "Action|Adventure|Sci-Fi       161\n",
       "Action|Drama|Thriller         159\n",
       "Comedy|Crime                  149\n",
       "Action|Adventure|Fantasy      135\n",
       "Action                        125\n",
       "Action|Comedy                 123\n",
       "Action|Horror|Sci-Fi          107\n",
       "Drama|Mystery|Thriller        100\n",
       "Action|Sci-Fi                  95\n",
       "Comedy|Drama|Music             92\n",
       "Drama|Romance|War              89\n",
       "Comedy|Musical|Romance         88\n",
       "Comedy|Drama|Fantasy           86\n",
       "Action|Sci-Fi|Thriller         84\n",
       "                             ... \n",
       "Drama|Musical|Family            1\n",
       "Action|Fantasy|Romance          1\n",
       "Action|Crime|Comedy             1\n",
       "Comedy|Romance|Fantasy          1\n",
       "Action|Biography                1\n",
       "Action|Crime|Sport              1\n",
       "Drama|Romance|Fantasy           1\n",
       "Comedy|Documentary|Music        1\n",
       "Comedy|Family|Adventure         1\n",
       "Drama|Fantasy|Western           1\n",
       "Action|Horror|Animation         1\n",
       "Drama|War|Western               1\n",
       "Action|Thriller|Mystery         1\n",
       "Comedy|Documentary|Family       1\n",
       "Drama|Fantasy|Sport             1\n",
       "Comedy|Romance|Music            1\n",
       "Comedy|Family|Western           1\n",
       "Action|Mystery|Romance          1\n",
       "Comedy|Thriller|Horror          1\n",
       "Action|Musical|Mystery          1\n",
       "Comedy|Music|Mystery            1\n",
       "Action|Musical|Drama            1\n",
       "Comedy|Romance|Family           1\n",
       "Action|Romance|War              1\n",
       "Drama|War|Comedy                1\n",
       "Comedy|Fantasy|Drama            1\n",
       "Comedy|Romance|Action           1\n",
       "Action|Adventure|Music          1\n",
       "Drama|Music|Sport               1\n",
       "Drama|Sport|War                 1\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the unique Genre present in data and their count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Genre.unique()\n",
    "print (uniqueGenre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13800, 330) (13800,)\n"
     ]
    }
   ],
   "source": [
    "cFeatures,cLabels = load_Features()\n",
    "cFeatures,cLabels = np.asarray(cFeatures),np.asarray(cLabels)\n",
    "print (cFeatures.shape,cLabels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into training data and testing data using sklearn train_test_split. The following is the definition of:\n",
    "\n",
    "**X_train**: This is a numpy array of feature vectors of the image for train the classifier.\n",
    "\n",
    "**X_test**:This is numpy array of lables of the images for training the classifier.\n",
    "\n",
    "**y_train**: This is a numpy array of feature vectors of the image for testing the classifier.\n",
    "\n",
    "**y_test** This is numpy array of lables of the images for testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10350, 2930), (3450, 2930), (10350,), (3450,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cFeatures, cLabels, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,chi2,SelectPercentile,SelectFpr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForestClassifier classifier and perform cross validation using GridSearchCV and feature selection using recursive cross validation. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search to tune the hyper parameters of the model\n",
      "Performing Pipeline Steps: ['clf']\n",
      "parameters are :\n",
      "{'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'clf__n_estimators': [10, 20, 50, 100],\n",
      " 'clf__random_state': [300, 400, 700]}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the classifier is 428.899471045\n",
      "\n",
      "Best score 0.53806763285\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 100\n",
      "\tclf__random_state: 700\n",
      "Time to test the classifier is 0.272365093231\n",
      "Calculated Accuracy is 0.53652173913\n",
      "Precision Score is 0.536992111399\n",
      "Recall Score is 0.53652173913\n",
      "F1 Score is 0.53551514228\n",
      "confusion matrix:\n",
      "[[578 253 302]\n",
      " [238 636 290]\n",
      " [320 309 524]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    #('rfe', RFECV(estimator=SVC(kernel='linear'),scoring='accuracy',cv=StratifiedKFold(),step=1)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [10,20,50,100],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__random_state':[300,400,700]\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "RandomForestModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing Pipeline Steps:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "RandomForestModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score {}\".format(RandomForestModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = RandomForestModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = RandomForestModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time() - t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier: \n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Time to train the model is 111.384582043\n",
      "Time to test the model is 0.302144050598\n",
      "confusion matrix:\n",
      "[[578 253 302]\n",
      " [238 636 290]\n",
      " [320 309 524]]\n",
      "Calculated Accuracy is 0.503768115942\n",
      "Precision Score is 0.503129353024\n",
      "Recall Score is 0.503768115942\n",
      "F1 Score is 0.503369729456\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "print(\"Training the classifier: \")\n",
    "print(clf)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Time to test the model is {}\".format(time() - t0))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "     ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', AdaBoostClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50,70,90],\n",
    "    'clf__random_state': [1,20,40]\n",
    "}\n",
    "AdaBoostModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "AdaBoostModel.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Best reported score is {}\".format(AdaBoostModel.best_score_))\n",
    "print(\"Best parameters set are: \"))\n",
    "best_parameters = AdaBoostModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {} \".format(param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = AdaBoostModel.predict(X_test)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(70, 20, 10), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
      "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
      "       warm_start=False)\n",
      "train time: 23.896s\n",
      "test time:  0.020s\n",
      "confusion matrix:\n",
      "[[251 339   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [165 894   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 63 343   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7 184   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8  71   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  5   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 17  44   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Calculated Accuracy is 0.449372056515\n",
      "Precision Score is 0.292459148706\n",
      "Recall Score is 0.449372056515\n",
      "F1 Score is 0.345142033894\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "print(\"Training the classifier...\")\n",
    "t0 = time()\n",
    "param_grid = {'hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "              'activation' :['logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'alpha':[ 0.0001, 0.001, 0.01]}\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid)\n",
    "print(clf)\n",
    "X_train = SelectKBest(chi2, k=2).fit_transform(X_train, y_train)\n",
    "X_test = SelectKBest(chi2, k=2).fit_transform(X_test, y_test)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('rf', KNeighb...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))],\n",
      "         n_jobs=1, voting='hard', weights=None)\n",
      "train time: 2.429s\n",
      "test time:  0.113s\n",
      "confusion matrix:\n",
      "[[262 325   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [182 867   2   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 83 311   2  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 14 166   1  10   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7  70   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 20  40   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  20   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3  24   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  21   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   4   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Calculated Accuracy is 0.447802197802\n",
      "Precision Score is 0.373941677883\n",
      "Recall Score is 0.447802197802\n",
      "F1 Score is 0.353217228967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'clf__solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'clf__alpha':[ 0.0001, 0.001, 0.001],\n",
    "    'clf__learning_rate':['constant', 'invscaling', 'adaptive']\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "\n",
    "MLPModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "MLPModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time()-t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( MLPModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = MLPModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = MLPModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time()-t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Scores using VotingClassifier. The classifiers used are LogisticRegression(),KNeighborsClassifier() and  MLPClassifier().  Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = MLPClassifier()\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3)], voting='hard')\n",
    "print(\"Training the classifier...\")\n",
    "print(eclf1)\n",
    "t0 = time()\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = eclf1.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "print(\"The confusion matrix: {}\".format(metrics.confusion_matrix(y_test, pred)))\n",
    "print(\"Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Train linear SVM  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly'),\n",
    "    'clf__C': (0.001,0.0001,0.01)\n",
    "}\n",
    "SVC_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( SVC_clf.best_score)_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVC by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {\n",
    "    'C': (0.001,0.0001,0.01,1)\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "SVC_clf = GridSearchCV(SVC(kernel=\"linear\"), parameters, n_jobs=-1, verbose=1)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\" \")\n",
    "print(\"Best score: %0.3f\" % SVC_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
