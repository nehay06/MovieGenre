{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColorDescriptor:\n",
    "    def __init__(self, bins):\n",
    "        # store the number of bins for the 3D histogram\n",
    "        self.bins = bins\n",
    " \n",
    "    def describe(self, image):\n",
    "        # convert the image to the HSV color space and initialize\n",
    "        # the features used to quantify the image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        features = []\n",
    " \n",
    "        # grab the dimensions and compute the center of the image\n",
    "        (h, w) = image.shape[:2]\n",
    "        (cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
    "        \n",
    "        # divide the image into four rectangles/segments (top-left,\n",
    "        # top-right, bottom-right, bottom-left)\n",
    "        segments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h),\n",
    "            (0, cX, cY, h)]\n",
    " \n",
    "        # construct an elliptical mask representing the center of the\n",
    "        # image\n",
    "        (axesX, axesY) = (int(w * 0.75) / 2, int(h * 0.75) / 2)\n",
    "        ellipMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "        cv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
    " \n",
    "        # loop over the segments\n",
    "        for (startX, endX, startY, endY) in segments:\n",
    "            # construct a mask for each corner of the image, subtracting\n",
    "            # the elliptical center from it\n",
    "            cornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "            cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
    "            cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
    " \n",
    "            # extract a color histogram from the image, then update the\n",
    "            # feature vector\n",
    "            hist = self.histogram(image, cornerMask)\n",
    "            features.extend(hist)\n",
    " \n",
    "        # extract a color histogram from the elliptical region and\n",
    "        # update the feature vector\n",
    "        hist = self.histogram(image, ellipMask)\n",
    "        features.extend(hist)\n",
    " \n",
    "        # return the feature vector\n",
    "        return features\n",
    "    def histogram(self, image, mask):\n",
    "        # extract a 3D color histogram from the masked region of the\n",
    "        # image, using the supplied number of bins per channel; then\n",
    "        # normalize the histogram\n",
    "        hist = cv2.calcHist([image], [0, 1, 2], mask, self.bins,\n",
    "            [0, 180, 0, 256, 0, 256])\n",
    "        hist = cv2.normalize(hist,hist).flatten()\n",
    "\n",
    "        # return the histogram\n",
    "        return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_var):\n",
    "    network = lasagne.layers.InputLayer(shape=(None,1, 100,100), input_var = input_var)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters = 100, filter_size = (3,3), stride = (2,2), pad = 'same',\n",
    "                                         nonlinearity = lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters = 50, filter_size = (3,3), stride = (2,2), pad = 'same',\n",
    "                                         nonlinearity = lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters = 25, filter_size = (3,3), stride = (2,2), pad = 'same',\n",
    "                                         nonlinearity = lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(network, num_units = 800, nonlinearity = lasagne.nonlinearities.rectify)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(network, num_units = 25, nonlinearity = lasagne.nonlinearities.softmax)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, Y, batchsize):\n",
    "    row, col, z, y = X.shape\n",
    "    for i in range(int(row/batchsize)) :\n",
    "        yield X[batchsize*i: batchsize*(i+1),:], Y[batchsize*i: batchsize*(i+1),:]\n",
    "#     print i*batchsize, row\n",
    "#     if i*batchsize < row:\n",
    "#         print \"I like you!\"\n",
    "#         yield X[batchsize*(i+1):,:], Y[batchsize*(i+1):,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_test, Y_test):\n",
    "    input_var = T.dtensor4(\"inputs\")\n",
    "    target_var = T.lmatrix(\"targets\")\n",
    "    X_train = X_train.reshape((-1,1,100,100))\n",
    "    X_test = X_test.reshape((-1,1,100,100))\n",
    "    network = build_model(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    \n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    #updates = lasagne.updates.rmsprop(loss, params, learning_rate=0.01, rho=0.9, epsilon=1e-06)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    \n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), T.argmax(target_var,axis = 1)),\n",
    "                  dtype=theano.config.floatX)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    num_epochs = 20\n",
    "    \n",
    "            \n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_acc = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for i,batch in enumerate(iterate_minibatches(X_train, Y_train, 100)):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            train_acc += acc\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_test, Y_test, 100):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  training accuracy:\\t\\t{:.2f} %\".format(\n",
    "            train_acc / train_batches * 100))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39263, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../GenresFullLabels.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1', 'Feature2']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import cv2\n",
    "def load_dataset():\n",
    "    imageDir = \"./../PostersResized40/\"  \n",
    "    imageData = np.zeros((38500,100,100))\n",
    "    outputData = np.zeros((38500,25),dtype=int)\n",
    "    cd = ColorDescriptor((8, 12, 3))\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[3]]\n",
    "        original_image = imread(imageDir+filename)\n",
    "        features = cd.describe(original_image)\n",
    "        print len(features)\n",
    "        imageData[index,:,:] = original_image\n",
    "        outputData[index,label] = 1\n",
    "        if index == 38499:\n",
    "            break\n",
    "    return imageData,outputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,100,3) into shape (100,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-03111d245995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimageData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mimageData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ce0a71a213e4>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mimageData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutputData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m38499\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (100,100,3) into shape (100,100)"
     ]
    }
   ],
   "source": [
    "imageData,labels = load_dataset()\n",
    "print imageData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print labels[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 100, 100)\n",
      "(None, 100, 50, 50)\n",
      "(None, 50, 25, 25)\n",
      "(None, 25, 13, 13)\n",
      "(None, 800)\n",
      "(None, 25)\n",
      "Epoch 1 of 20 took 997.919s\n",
      "  training loss:\t\t2.179745\n",
      "  training accuracy:\t\t29.85 %\n",
      "  validation loss:\t\t2.147997\n",
      "  validation accuracy:\t\t28.78 %\n",
      "Epoch 2 of 20 took 813.223s\n",
      "  training loss:\t\t2.128612\n",
      "  training accuracy:\t\t30.93 %\n",
      "  validation loss:\t\t2.139650\n",
      "  validation accuracy:\t\t29.62 %\n",
      "Epoch 3 of 20 took 798.240s\n",
      "  training loss:\t\t2.109776\n",
      "  training accuracy:\t\t31.47 %\n",
      "  validation loss:\t\t2.142338\n",
      "  validation accuracy:\t\t29.45 %\n",
      "Epoch 4 of 20 took 1475.308s\n",
      "  training loss:\t\t2.086660\n",
      "  training accuracy:\t\t32.54 %\n",
      "  validation loss:\t\t2.153209\n",
      "  validation accuracy:\t\t28.87 %\n",
      "Epoch 5 of 20 took 873.564s\n",
      "  training loss:\t\t2.049530\n",
      "  training accuracy:\t\t34.39 %\n",
      "  validation loss:\t\t2.176484\n",
      "  validation accuracy:\t\t28.49 %\n",
      "Epoch 6 of 20 took 735.068s\n",
      "  training loss:\t\t1.985407\n",
      "  training accuracy:\t\t38.10 %\n",
      "  validation loss:\t\t2.212893\n",
      "  validation accuracy:\t\t27.99 %\n",
      "Epoch 7 of 20 took 1003.433s\n",
      "  training loss:\t\t1.872867\n",
      "  training accuracy:\t\t44.27 %\n",
      "  validation loss:\t\t2.278756\n",
      "  validation accuracy:\t\t27.55 %\n",
      "Epoch 8 of 20 took 786.133s\n",
      "  training loss:\t\t1.678320\n",
      "  training accuracy:\t\t55.30 %\n",
      "  validation loss:\t\t2.414875\n",
      "  validation accuracy:\t\t26.71 %\n",
      "Epoch 9 of 20 took 1538.946s\n",
      "  training loss:\t\t1.366631\n",
      "  training accuracy:\t\t70.92 %\n",
      "  validation loss:\t\t2.673726\n",
      "  validation accuracy:\t\t24.69 %\n",
      "Epoch 10 of 20 took 1670.198s\n",
      "  training loss:\t\t0.960184\n",
      "  training accuracy:\t\t86.27 %\n",
      "  validation loss:\t\t3.081545\n",
      "  validation accuracy:\t\t24.04 %\n",
      "Epoch 11 of 20 took 968.880s\n",
      "  training loss:\t\t0.582538\n",
      "  training accuracy:\t\t95.35 %\n",
      "  validation loss:\t\t3.431639\n",
      "  validation accuracy:\t\t22.33 %\n",
      "Epoch 12 of 20 took 1131.766s\n",
      "  training loss:\t\t0.371656\n",
      "  training accuracy:\t\t98.48 %\n",
      "  validation loss:\t\t3.685733\n",
      "  validation accuracy:\t\t21.88 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4e920860ad77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-ac79a9a3199c>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imageData, labels, test_size=0.25, random_state=42)\n",
    "network = train_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 1 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [1 0 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print YVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "print type(XVal)\n",
    "def testAccuracy(X_test,Y_test):\n",
    "    X_test = X_test.reshape((-1,1,100,100))\n",
    "    predictedLabels = lasagne.layers.get_output(network,inputs = X_test).eval()\n",
    "    return predictedLabels\n",
    "predictedLabels = testAccuracy(XVal,YVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n",
      "(1000, 20)\n",
      "[[1 0 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 1 0 ..., 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print predictedLabels.shape\n",
    "print YVal.shape\n",
    "Y_Pred = np.zeros(predictedLabels.shape,dtype = int)\n",
    "rows = np.argmax(predictedLabels, axis=1)\n",
    "for i in range(YVal.shape[0]):\n",
    "    Y_Pred[i,rows[i]] = 1\n",
    "print  Y_Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported Accuracy is 0.367\n",
      "precision_score is 0.349254336852\n",
      "recall_score is 0.367\n",
      "f1_score is 0.304249177662\n"
     ]
    }
   ],
   "source": [
    "Y_test = YVal\n",
    "accuracyscore = accuracy_score(Y_test, Y_Pred)\n",
    "f1score = f1_score(Y_test, Y_Pred, average='weighted') \n",
    "precisionscore = precision_score(Y_test, Y_Pred, average='weighted')\n",
    "recallscore = recall_score(Y_test, Y_Pred, average='weighted') \n",
    "print(\"Reported Accuracy is {}\".format(accuracyscore))\n",
    "print(\"precision_score is {}\".format(precisionscore))\n",
    "print(\"recall_score is {}\".format(recallscore))\n",
    "print(\"f1_score is {}\".format(f1score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
