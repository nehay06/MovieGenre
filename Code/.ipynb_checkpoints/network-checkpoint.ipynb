{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_var):\n",
    "    network = lasagne.layers.InputLayer(shape=(None,1, 100,100), input_var = input_var)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters = 100, filter_size = (3,3), pad = 'same',\n",
    "                                         nonlinearity = lasagne.nonlinearities.tanh)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size = (2,2))\n",
    "    \n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.Conv2DLayer(network, num_filters = 50, filter_size = (3,3), pad = 'same',\n",
    "                                         nonlinearity = lasagne.nonlinearities.tanh)\n",
    "    \n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    network = lasagne.layers.MaxPool2DLayer(network, pool_size = (2,2))\n",
    "    \n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "        \n",
    "    network = lasagne.layers.DenseLayer(network, num_units = 800, nonlinearity = lasagne.nonlinearities.rectify)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    network = lasagne.layers.DenseLayer(network, num_units = 25, nonlinearity = lasagne.nonlinearities.softmax)\n",
    "    print lasagne.layers.get_output_shape(network)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, Y, batchsize):\n",
    "    row, col, z, y = X.shape\n",
    "    for i in range(int(row/batchsize)) :\n",
    "        yield X[batchsize*i: batchsize*(i+1),:], Y[batchsize*i: batchsize*(i+1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_test, Y_test):\n",
    "    input_var = T.dtensor4(\"inputs\")\n",
    "    target_var = T.lmatrix(\"targets\")\n",
    "    X_train = X_train.reshape((-1,1,100,100))\n",
    "    X_test = X_test.reshape((-1,1,100,100))\n",
    "    network = build_model(input_var)\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "    \n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "    loss = loss.mean()\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "    \n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), T.argmax(target_var,axis = 1)),\n",
    "                  dtype=theano.config.floatX)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc])\n",
    "    num_epochs = 20\n",
    "    \n",
    "            \n",
    "    for epoch in range(num_epochs):\n",
    "        # In each epoch, we do a full pass over the training data:\n",
    "        train_err = 0\n",
    "        train_acc = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        for i,batch in enumerate(iterate_minibatches(X_train, Y_train, 100)):\n",
    "            inputs, targets = batch\n",
    "            train_err += train_fn(inputs, targets)\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            train_acc += acc\n",
    "            train_batches += 1\n",
    "\n",
    "        # And a full pass over the validation data:\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(X_test, Y_test, 100):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"  training accuracy:\\t\\t{:.2f} %\".format(\n",
    "            train_acc / train_batches * 100))\n",
    "        print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "            val_acc / val_batches * 100))\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39263, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Animation|Adventure|Comedy</td>\n",
       "      <td>114709</td>\n",
       "      <td>Animation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Action|Adventure|Family</td>\n",
       "      <td>113497</td>\n",
       "      <td>Action</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>113228</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>114885</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comedy|Family|Romance</td>\n",
       "      <td>113041</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Genre  imdbId   Feature1  Feature2\n",
       "0  Animation|Adventure|Comedy  114709  Animation         0\n",
       "1     Action|Adventure|Family  113497     Action         1\n",
       "2              Comedy|Romance  113228     Comedy         2\n",
       "3        Comedy|Drama|Romance  114885     Comedy         2\n",
       "4       Comedy|Family|Romance  113041     Comedy         2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../Dataset/GenresFullLabels.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1', 'Feature2']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Feature1.unique()\n",
    "print(uniqueGenre.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "def load_dataset():\n",
    "    imageDir = \"./../Dataset/PostersResized40/\"  \n",
    "    imageData = np.zeros((39263,100,100))\n",
    "    outputData = np.zeros((39263,25),dtype=int)\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[3]]\n",
    "        original_image = imread(imageDir+filename,as_grey=True)\n",
    "        imageData[index,:,:] = original_image\n",
    "        outputData[index,label] = 1\n",
    "    return imageData,outputData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageData,labels = load_dataset()\n",
    "print imageData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print labels[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 100, 100)\n",
      "(None, 100, 100, 100)\n",
      "(None, 100, 50, 50)\n",
      "(None, 50, 50, 50)\n",
      "(None, 50, 25, 25)\n",
      "(None, 800)\n",
      "(None, 25)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(imageData, labels, test_size=0.25, random_state=42)\n",
    "network = train_model(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "def testAccuracy(X_test,Y_test):\n",
    "    X_test = X_test.reshape((-1,1,100,100))\n",
    "    predictedLabels = lasagne.layers.get_output(network,inputs = X_test).eval()\n",
    "    return predictedLabels\n",
    "predictedLabels = testAccuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 6)\n",
      "(435, 6)\n",
      "[[0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0]\n",
      " ..., \n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 0 1 0]\n",
      " [0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print predictedLabels.shape\n",
    "print y_test.shape\n",
    "Y_Pred = np.zeros(predictedLabels.shape,dtype = int)\n",
    "rows = np.argmax(predictedLabels, axis=1)\n",
    "for i in range(y_test.shape[0]):\n",
    "    Y_Pred[i,rows[i]] = 1\n",
    "print  Y_Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reported Accuracy is 0.298850574713\n",
      "precision_score is 0.299030896035\n",
      "recall_score is 0.298850574713\n",
      "f1_score is 0.296188755528\n"
     ]
    }
   ],
   "source": [
    "Y_test = y_test\n",
    "accuracyscore = accuracy_score(Y_test, Y_Pred)\n",
    "f1score = f1_score(Y_test, Y_Pred, average='weighted') \n",
    "precisionscore = precision_score(Y_test, Y_Pred, average='weighted')\n",
    "recallscore = recall_score(Y_test, Y_Pred, average='weighted') \n",
    "print(\"Reported Accuracy is {}\".format(accuracyscore))\n",
    "print(\"precision_score is {}\".format(precisionscore))\n",
    "print(\"recall_score is {}\".format(recallscore))\n",
    "print(\"f1_score is {}\".format(f1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
