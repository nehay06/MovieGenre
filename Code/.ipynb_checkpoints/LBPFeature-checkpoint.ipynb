{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the getLBPFeatures method to fetch the local Binary patterns of the image. Local Binary Patterns compute the local representation of the texture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLBPFeatures(image,numPoints, radius):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image: input image (greyscale) as numpy array\n",
    "    :param numPoints:number of points p in a circularly symmetric neighborhood of central pixel\n",
    "    :param radius: radius of the circle\n",
    "    :return: histogram of Local binary pattern of given image\n",
    "    \"\"\"\n",
    "    lbp = feature.local_binary_pattern(image, numPoints,\n",
    "            radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(),\n",
    "            bins=np.arange(0, numPoints + 3),\n",
    "            range=(0, numPoints + 2))\n",
    "    # normalize the histogram\n",
    "    eps=1e-7\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + eps)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the mean,standard deviation,skewness and HUEMoments of the input image.It returns a feature vector as numpy array which embeds the mentioned features. The image is read into HSV color space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getMoments(image):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image: input image\n",
    "    :return: numpy array which contains the mean,standard deviation,skewness and heuMoments of the image\n",
    "    \"\"\"\n",
    "\n",
    "    #read the image in HSV color space\n",
    "    imageHSV = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    #calculate the mean and standard deviation of the image\n",
    "    (means, stds) = cv2.meanStdDev(imageHSV)\n",
    "\n",
    "    #calculate the image moments\n",
    "    moments = cv2.moments(imageHSV[:,:,0])\n",
    "    skew0 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    moments = cv2.moments(imageHSV[:,:,1])\n",
    "    skew1 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    moments = cv2.moments(imageHSV[:,:,2])\n",
    "    skew2 = moments['mu11'] / moments['mu02'] if moments['mu02'] !=0 else moments['mu11']\n",
    "    skew = np.asarray([skew0,skew1,skew2]).reshape((3, 1))\n",
    "\n",
    "    #concatenate the mean,standard deviation,skew features into a single numpy array\n",
    "    stats = np.concatenate([means, stds,skew]).flatten()\n",
    "\n",
    "    #calculate the HuMoments of the image\n",
    "    imageGray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    Moments = cv2.HuMoments(cv2.moments(imageGray)).flatten()\n",
    "    moments = np.asarray(Moments)\n",
    "\n",
    "    #form the final feature vector which contains the mean,standard deviation, skewness and HueMoments of the image\n",
    "    finalFeatureVector = np.append(stats,moments)\n",
    "\n",
    "    #return the feature vector\n",
    "    return finalFeatureVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV file into panda dataframe. The column names description:\n",
    "\n",
    "**Genre** : Genre for the given File\n",
    "\n",
    "**imdbId**: Image file name (File names are the imdbID for the given movie)\n",
    "\n",
    "**Feature1**: Label assigned to image file with given Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Action|Adventure|Drama</td>\n",
       "      <td>35153</td>\n",
       "      <td>Action</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama</td>\n",
       "      <td>1630036</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1195478</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Action|Crime</td>\n",
       "      <td>79966</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama|History</td>\n",
       "      <td>1029364</td>\n",
       "      <td>Drama</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Genre   imdbId Feature1  Feature2\n",
       "0  Action|Adventure|Drama    35153   Action         0\n",
       "1                   Drama  1630036    Drama         1\n",
       "2          Comedy|Romance  1195478   Comedy         2\n",
       "3     Comedy|Action|Crime    79966   Comedy         2\n",
       "4           Drama|History  1029364    Drama         1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./../Dataset/Top3FullGenre.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the counts of each Genre category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama                       4205\n",
       "Comedy                      2408\n",
       "Comedy|Drama                1474\n",
       "Drama|Romance               1448\n",
       "Comedy|Drama|Romance        1130\n",
       "Comedy|Romance              1002\n",
       "Action|Crime|Drama           558\n",
       "Drama|Thriller               509\n",
       "Drama|War                    321\n",
       "Comedy|Crime|Drama           289\n",
       "Action|Comedy|Crime          275\n",
       "Action|Adventure|Drama       264\n",
       "Action|Crime|Thriller        256\n",
       "Comedy|Crime                 247\n",
       "Action|Adventure|Comedy      245\n",
       "Drama|Mystery|Thriller       199\n",
       "Comedy|Horror                194\n",
       "Action|Drama                 183\n",
       "Comedy|Drama|Family          169\n",
       "Action|Thriller              167\n",
       "Drama|History                166\n",
       "Action|Drama|Thriller        164\n",
       "Action|Adventure|Sci-Fi      163\n",
       "Comedy|Drama|Music           147\n",
       "Drama|Horror|Thriller        141\n",
       "Action|Adventure|Fantasy     137\n",
       "Comedy|Musical|Romance       136\n",
       "Drama|Horror|Mystery         135\n",
       "Drama|Family                 134\n",
       "Action                       131\n",
       "                            ... \n",
       "Action|Fantasy|History         1\n",
       "Drama|Fantasy|Family           1\n",
       "Drama|Documentary|Music        1\n",
       "Drama|Horror|Fantasy           1\n",
       "Comedy|Romance|Adventure       1\n",
       "Action|Comedy|Animation        1\n",
       "Action|War|Western             1\n",
       "Drama|Sci-Fi|Crime             1\n",
       "Drama|Mystery|Music            1\n",
       "Drama|Family|Mystery           1\n",
       "Action|Western|Adventure       1\n",
       "Comedy|History|Music           1\n",
       "Comedy|Action|Family           1\n",
       "Drama|Fantasy|Sport            1\n",
       "Drama|Sci-Fi|Romance           1\n",
       "Action|Musical|Mystery         1\n",
       "Drama|Mystery|News             1\n",
       "Drama|Sci-Fi|Horror            1\n",
       "Drama|Short|Fantasy            1\n",
       "Comedy|Fantasy|Drama           1\n",
       "Drama|Sport|Western            1\n",
       "Drama|Musical|Sport            1\n",
       "Comedy|Documentary|Drama       1\n",
       "Drama|Music|Sport              1\n",
       "Drama|Comedy|Family            1\n",
       "Action|Horror|Western          1\n",
       "Comedy|War|Fantasy             1\n",
       "Comedy|Family|War              1\n",
       "Drama|War|Comedy               1\n",
       "Comedy|Action|Thriller         1\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the columns of the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1', 'Feature2']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the unique feature and print it's count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Feature1.unique()\n",
    "print(uniqueGenre.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itertate over all the movie posters, compute their Local Binary Patterns features and associated labels.\n",
    "It return the feature vector containing the local binary patterns and lables indicating the Genre associated with the movie poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_LBP_features():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = imread(imageDir+filename,as_grey= True)\n",
    "        hist = getLBPFeatures(original_image,40,8)\n",
    "        inputData.append(hist)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itertate over all the movie posters, compute their moments  and associated labels. It also computes their Local Binary patterns features and associated labels.\n",
    "It return the feature vector containing image moments and local binary patterns and labels indicating the Genre associated with the movie poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_moment_features():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = imread(imageDir+filename)\n",
    "        hist = getMoments(original_image)\n",
    "        inputData.append(hist)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Itertate over all the movie posters, compute their moments,Local Binary pattersn  and associated labels.\n",
    "It return the feature vector containing image moments, local binary pattern features and lables indicating the Genre associated with the movie poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_combined_features():\n",
    "    imageDir = \"./../Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = imread(imageDir+filename)\n",
    "        Moments = getMoments(original_image)\n",
    "        original_image = imread(imageDir+filename,as_grey=True)\n",
    "        LBPFeatures = getLBPFeatures(original_image,40,8)\n",
    "        inputData.append(np.append(LBPFeatures,Moments))\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the LBP Features of all the movie posters in the dataset and associated label indicating the Genre. The lbpFeatures is a numpy array of N X NUMBER OF LBP FEATURES. N denotes the total number of movie posters. The labels are the numpy array of N X 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbpFeatures,labels = load_LBP_features()\n",
    "lbpFeatures,labels = np.asarray(lbpFeatures),np.asarray(labels)\n",
    "print (lbpFeatures.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the LBP Features and image moments(mean,standard deviation,skewness and HUEMoments) of all the movie posters in the dataset and associated label indicating the Genre. The lbpFeatures is a numpy array of N X Number of LBP Features +Image moments N denotes the total number of movie posters. The labels are the numpy array of N X 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cFeatures,labels = load_combined_features()\n",
    "cFeatures,labels = np.asarray(cFeatures),np.asarray(labels)\n",
    "print (cFeatures.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into training data and testing data using sklearn train_test_split. The following is the definition of:\n",
    "\n",
    "**X_train**: This is a numpy array of feature vectors of the image for train the classifier.\n",
    "\n",
    "**X_test**:This is numpy array of lables of the images for training the classifier.\n",
    "\n",
    "**y_train**: This is a numpy array of feature vectors of the image for testing the classifier.\n",
    "\n",
    "**y_test** This is numpy array of lables of the images for testing the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7642, 58), (2548, 58), (7642,), (2548,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cFeatures, labels, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined all the modules to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train RandomForestClassifier classifier and perform cross validation using GridSearchCV. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search to tune the hyper parameters of the model\n",
      "Performing Pipeline Steps: ['clf']\n",
      "parameters are :\n",
      "{'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'clf__n_estimators': [10, 20, 50, 100],\n",
      " 'clf__random_state': [300, 400, 700]}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the classifier is 126.436920166\n",
      "\n",
      "Best score 0.468071185554\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 100\n",
      "\tclf__random_state: 400\n",
      "Time to test the classifier is 0.262647151947\n",
      "Calculated Accuracy is 0.472135007849\n",
      "Precision Score is 0.489173307935\n",
      "Recall Score is 0.472135007849\n",
      "F1 Score is 0.402710564222\n",
      "confusion matrix:\n",
      "[[275 300  14   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [168 851  38   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 63 278  63   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7 158  15  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8  67   3   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  5   3   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 20  38   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  17   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3  15   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  18   3   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   4   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   7   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=AdaBoostClassifier(),scoring='accuracy',cv=StratifiedKFold(3),step=1)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [10,20,50,100],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__random_state':[300,400,700]\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "RandomForestModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing Pipeline Steps:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "RandomForestModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score {}\".format(RandomForestModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = RandomForestModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = RandomForestModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time() - t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Scores using VotingClassifier. The classifiers used are LogisticRegression(),KNeighborsClassifier() and  MLPClassifier().  Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier...\n",
      "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)), ('rf', KNeighb...=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False))],\n",
      "         n_jobs=1, voting='hard', weights=None)\n",
      "Time to train the classifier is 6.37550592422\n",
      "Time to test the classifier is 1.25316596031\n",
      "The confusion matrix: [[692 312 129]\n",
      " [346 709 109]\n",
      " [513 439 201]]\n",
      "Accuracy is 0.464347826087\n",
      "Precision Score is 0.463383258573\n",
      "Recall Score is 0.464347826087\n",
      "F1 Score is 0.436057343358\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = MLPClassifier()\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3)], voting='hard')\n",
    "print(\"Training the classifier...\")\n",
    "print(eclf1)\n",
    "t0 = time()\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = eclf1.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "print(\"The confusion matrix: {}\".format(metrics.confusion_matrix(y_test, pred)))\n",
    "print(\"Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search to tune the hyper parameters of the model\n",
      "pipeline : ['clf']\n",
      "parameters are :\n",
      "{'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
      " 'clf__alpha': [0.0001, 0.001, 0.001],\n",
      " 'clf__hidden_layer_sizes': [(70, 20, 10), (40, 20, 10), (90, 20, 10)],\n",
      " 'clf__solver': ['lbfgs', 'sgd', 'adam']}\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 324 out of 324 | elapsed:  8.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the classifier is 518.967584848\n",
      "\n",
      "Best score:0.443961352657\n",
      "Best parameters set:\n",
      "\tclf__activation: 'tanh'\n",
      "\tclf__alpha: 0.001\n",
      "\tclf__hidden_layer_sizes: (40, 20, 10)\n",
      "\tclf__solver: 'lbfgs'\n",
      "Time to test the classifier is 0.0170249938965\n",
      "Calculated Accuracy is 0.446376811594\n",
      "Precision Score is 0.444648781614\n",
      "Recall Score is 0.446376811594\n",
      "F1 Score is 0.428113344498\n",
      "confusion matrix:\n",
      "[[694 288 151]\n",
      " [438 560 166]\n",
      " [486 419 248]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "    #('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'clf__solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'clf__alpha':[ 0.0001, 0.001, 0.001]\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "\n",
    "MLPModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline :\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters are :\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "MLPModel.fit(X_train, y_train)\n",
    "print(\"Time to train the classifier is {}\".format(time()-t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( MLPModel.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = MLPModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "t0 = time()\n",
    "predicted = MLPModel.predict(X_test)\n",
    "print(\"Time to test the classifier is {}\".format(time()-t0))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MultiLayer Perceptron by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier...\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': [0.0001, 0.001, 0.01], 'activation': ['logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'hidden_layer_sizes': [(70, 20, 10), (40, 20, 10), (50, 20, 10)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the classifier is 1447.73412108\n",
      "Time to test the classifier is 0.0211679935455\n",
      "confusion matrix:\n",
      "[[236 354   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [184 873   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 69 335   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 12 176   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  74   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 20  41   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  15   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  23   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  7   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Calculated Accuracy is 0.436420722135\n",
      "Precision Score is 0.306589815234\n",
      "Recall Score is 0.436420722135\n",
      "F1 Score is 0.336190381952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "print(\"Training the classifier...\")\n",
    "t0 = time()\n",
    "param_grid = {'hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(50, 20, 10)],\n",
    "              'activation' :['logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'alpha':[ 0.0001, 0.001, 0.01]}\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid)\n",
    "print(clf)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"Time to train the classifier is {}\".format(train_time))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"Time to test the classifier is {}\".format(test_time))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline Parameters: ['clf']\n",
      "Chosen Parameters: are\n",
      "{'clf__n_estimators': [50, 70, 90], 'clf__random_state': [1, 20, 40]}\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   45.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model is 49.6613788605\n",
      "\n",
      "Best reported score is 0.380266945826\n",
      "Best parameters set are: \n",
      "clf__n_estimators: 50 \n",
      "clf__random_state: 1 \n",
      "confusion matrix:\n",
      "[[298 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [289 758   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12\n",
      "    0   0]\n",
      " [ 89 309   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "    0   0]\n",
      " [ 18 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  9  67   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [  6   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 29  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  5  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [  2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Calculated Accuracy is 0.414442700157\n",
      "Precision Score is 0.269830251373\n",
      "Recall Score is 0.414442700157\n",
      "F1 Score is 0.325948066979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "     #('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', AdaBoostClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50,70,90],\n",
    "    'clf__random_state': [1,20,40]\n",
    "}\n",
    "AdaBoostModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "AdaBoostModel.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Best reported score is {}\".format(AdaBoostModel.best_score_))\n",
    "print(\"Best parameters set are: \")\n",
    "best_parameters = AdaBoostModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"{}: {} \".format(param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = AdaBoostModel.predict(X_test)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train AdaBoostClassifier. Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the classifier: \n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "Time to train the model is 2.84198689461\n",
      "Time to test the model is 0.0790550708771\n",
      "confusion matrix:\n",
      "[[298 289   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [289 758   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  12\n",
      "    0   0]\n",
      " [ 89 309   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   8\n",
      "    0   0]\n",
      " [ 18 172   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1\n",
      "    0   0]\n",
      " [  9  67   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [  6   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 29  32   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  18   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  5  14   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  19   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "    0   0]\n",
      " [  2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  8   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Calculated Accuracy is 0.414442700157\n",
      "Precision Score is 0.269830251373\n",
      "Recall Score is 0.414442700157\n",
      "F1 Score is 0.325948066979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "print(\"Training the classifier: \")\n",
    "print(clf)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Time to test the model is {}\".format(time() - t0))\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train linear SVM  by performing feature selection and cross validation. The feature selection is perform using Recursive feature selection with cross validation and hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly'),\n",
    "    'clf__C': (0.001,0.0001,0.01)\n",
    "}\n",
    "SVC_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"pipeline Parameters:\", [name for name, _ in pipeline.steps])\n",
    "print(\"Chosen Parameters: are\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score:{}\".format( SVC_clf.best_score_))\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train SVC by performing cross validation to tune the hyper parameters of the classifier. The hyper parameter tuning is performed GridSearchCV. \n",
    "Compute confusion matrix, Precision score,accuracy,recall score and f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "parameters = {\n",
    "    'C': (0.001,0.0001,0.01,1)\n",
    "}\n",
    "print(\"Performing Grid Search to tune the hyper parameters of the model\")\n",
    "SVC_clf = GridSearchCV(SVC(kernel=\"linear\"), parameters, n_jobs=-1, verbose=1)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"Time to train the model is {}\".format(time() - t0))\n",
    "print(\" \")\n",
    "print(\"Best score: %0.3f\" % SVC_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
