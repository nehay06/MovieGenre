{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "from skimage import feature\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.misc\n",
    "from skimage.io import imread\n",
    "import os\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>imdbId</th>\n",
       "      <th>Feature1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>113101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drama</td>\n",
       "      <td>114117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Drama</td>\n",
       "      <td>110299</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>115683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama</td>\n",
       "      <td>114753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Genre  imdbId  Feature1\n",
       "0  Comedy  113101         0\n",
       "1   Drama  114117         1\n",
       "2   Drama  110299         1\n",
       "3  Comedy  115683         0\n",
       "4   Drama  114753         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/nehayadav/Downloads/MLProject/Dataset/SingleGenres.csv\",delimiter=\",\").fillna(\"-NA-\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Genre', 'imdbId', 'Feature1']\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Drama          4205\n",
       "Comedy         2408\n",
       "Documentary    1559\n",
       "Horror          715\n",
       "Thriller        329\n",
       "Western         292\n",
       "Action          131\n",
       "Sci-Fi           91\n",
       "Short            85\n",
       "Family           59\n",
       "Adventure        51\n",
       "Crime            45\n",
       "Romance          45\n",
       "Mystery          44\n",
       "Musical          38\n",
       "Fantasy          27\n",
       "Animation        23\n",
       "Music            17\n",
       "Biography        14\n",
       "War              12\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "uniqueGenre = df.Genre.unique()\n",
    "print uniqueGenre.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSIFTFeatures(image):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBOWTrain():\n",
    "    imageDir = \"/Users/nehayadav/Downloads/MLProject/Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    bow_train = cv2.BOWKMeansTrainer(20)\n",
    "    detect = cv2.xfeatures2d.SIFT_create()\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename,0)\n",
    "        keypoints, descriptors = getSIFTFeatures(original_image)\n",
    "        bow_train.add(descriptors)\n",
    "    return bow_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_train = getBOWTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadBOWFeatures(bow_train):\n",
    "    flann_params = dict(algorithm = 1, trees = 5) \n",
    "    matcher = cv2.FlannBasedMatcher(flann_params, dict(checks=50))\n",
    "    voc = bow_train.cluster()\n",
    "    extract = cv2.xfeatures2d.SIFT_create()\n",
    "    detect = cv2.xfeatures2d.SIFT_create()\n",
    "    bow_extract = cv2.BOWImgDescriptorExtractor( extract, cv2.BFMatcher(cv2.NORM_L2) )\n",
    "    bow_extract.setVocabulary( voc )\n",
    "    imageDir = \"/Users/nehayadav/Downloads/MLProject/Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image =cv2.imread(imageDir+filename,0) \n",
    "        bowFeatures = bow_extract.compute(original_image, detect.detect(original_image))\n",
    "        inputData.extend(bowFeatures)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSIFTFeatures():\n",
    "    imageDir = \"/Users/nehayadav/Downloads/MLProject/Dataset/MovieGenreFullPosters/\"  \n",
    "    inputData = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows(): \n",
    "        filename = str(row[columns[1]])+\".jpg\"\n",
    "        label = row[columns[2]]\n",
    "        original_image = cv2.imread(imageDir+filename,0)\n",
    "        keypoints, descriptors = getSIFTFeatures(original_image)\n",
    "        inputData.extend(descriptors)\n",
    "        labels.append(label)\n",
    "    return inputData,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10190, 20) (10190,)\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "BOWFeatures,BOWLabels = loadBOWFeatures(bow_train)\n",
    "test_time = time() - t0\n",
    "print(\"Feature Extraction time:  %0.3fs\" % test_time)\n",
    "BOWFeatures,BOWLabels = np.asarray(BOWFeatures),np.asarray(BOWLabels)\n",
    "print BOWFeatures.shape , BOWLabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIFTFeatures,SIFTLabels = loadSIFTFeatures()\n",
    "SIFTFeatures,SIFTLabels = np.asarray(SIFTFeatures),np.asarray(SIFTLabels)\n",
    "print (SIFTFeatures.shape,SIFTLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((7642, 20), (2548, 20), (7642,), (2548,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(BOWFeatures, BOWLabels, test_size=0.25, random_state=42)\n",
    "X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,chi2,SelectPercentile,SelectFpr\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "train time: 29.776s\n",
      "test time:  1.463s\n",
      "confusion matrix:\n",
      "[[218 359  12   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [131 896  29   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 59 302  43   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 12 166   7   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 13  63   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [ 18  42   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   5   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   8   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  6  13   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2  26   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  4  13   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1  20   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   5   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   6   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  1   7   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  3   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  2   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]]\n",
      "Calculated Accuracy is 0.457613814757\n",
      "Precision Score is 0.461855492817\n",
      "Recall Score is 0.457613814757\n",
      "F1 Score is 0.37550418604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "print(\"Training: \")\n",
    "clf = RandomForestClassifier(n_estimators=700)\n",
    "#print(clf)\n",
    "t0 = time()\n",
    "param_grid = {'n_estimators': [100, 400, 500, 700, 1000],\n",
    "              'max_features': ['auto', 'sqrt','log2'] }\n",
    "#clf = GridSearchCV(RandomForestClassifier(), param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
      " 'clf__n_estimators': [10, 20, 50, 100],\n",
      " 'clf__random_state': [300, 400, 700]}\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 411.294s\n",
      "\n",
      "Best score: 0.454\n",
      "Best parameters set:\n",
      "\tclf__max_features: 'auto'\n",
      "\tclf__n_estimators: 100\n",
      "\tclf__random_state: 300\n",
      "Calculated Accuracy is 0.451334379906\n",
      "Precision Score is 0.456019676402\n",
      "Recall Score is 0.451334379906\n",
      "F1 Score is 0.376279529905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=RandomForestClassifier(),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', RandomForestClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [10,20,50,100],\n",
    "    'clf__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'clf__random_state':[300,400,700]\n",
    "}\n",
    "MLPModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "MLPModel.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % MLPModel.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = MLPModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = MLPModel.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "train time: 1.766s\n",
      "test time:  0.067s\n",
      "confusion matrix:\n",
      "[[   0  568    0    0    0    0    0    0   16    0    0    0    0    0\n",
      "     6    0    0    0    0    0]\n",
      " [   0 1017    0    0    0    0    0    0   18    0    0    0    0    0\n",
      "    24    0    0    0    0    0]\n",
      " [   0  388    0    0    0    0    0    0   12    0    0    0    0    0\n",
      "     6    0    0    0    0    0]\n",
      " [   0  185    0    0    0    0    0    0    1    0    0    0    0    0\n",
      "     5    0    0    0    0    0]\n",
      " [   0   72    0    0    0    0    0    0    4    0    0    0    0    0\n",
      "     3    0    0    0    0    0]\n",
      " [   0   10    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   58    0    0    0    0    0    0    3    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    9    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   20    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   27    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    0    0    0    0    0]\n",
      " [   0   19    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   21    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     2    0    0    0    0    0]\n",
      " [   0    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   12    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    4    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]]\n",
      "Calculated Accuracy is 0.399136577708\n",
      "Precision Score is 0.172736263095\n",
      "Recall Score is 0.399136577708\n",
      "F1 Score is 0.241121298227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier()\n",
    "print(\"Training: \")\n",
    "print(clf)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__n_estimators': [50, 70, 90], 'clf__random_state': [1, 20, 40]}\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 308.742s\n",
      "\n",
      "Best score: 0.407\n",
      "Best parameters set:\n",
      "\tclf__n_estimators: 50\n",
      "\tclf__random_state: 1\n",
      "confusion matrix:\n",
      "[[   0  568    0    0    0    0    0    0   16    0    0    0    0    0\n",
      "     6    0    0    0    0    0]\n",
      " [   0 1017    0    0    0    0    0    0   18    0    0    0    0    0\n",
      "    24    0    0    0    0    0]\n",
      " [   0  388    0    0    0    0    0    0   12    0    0    0    0    0\n",
      "     6    0    0    0    0    0]\n",
      " [   0  185    0    0    0    0    0    0    1    0    0    0    0    0\n",
      "     5    0    0    0    0    0]\n",
      " [   0   72    0    0    0    0    0    0    4    0    0    0    0    0\n",
      "     3    0    0    0    0    0]\n",
      " [   0   10    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   58    0    0    0    0    0    0    3    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    9    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   20    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   27    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     1    0    0    0    0    0]\n",
      " [   0   19    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   21    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     2    0    0    0    0    0]\n",
      " [   0    3    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    8    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    6    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0   12    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]\n",
      " [   0    4    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0]]\n",
      "Calculated Accuracy is 0.399136577708\n",
      "Precision Score is 0.172736263095\n",
      "Recall Score is 0.399136577708\n",
      "F1 Score is 0.241121298227\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "     ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', AdaBoostClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_estimators': [50,70,90],\n",
    "    'clf__random_state': [1,20,40]\n",
    "}\n",
    "AdaBoostModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "AdaBoostModel.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % AdaBoostModel.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = AdaBoostModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = AdaBoostModel.predict(X_test)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: \n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=1,\n",
      "       param_grid={'alpha': [0.0001, 0.001, 0.01], 'activation': ['identity', 'logistic', 'tanh', 'relu'], 'solver': ['lbfgs', 'sgd', 'adam'], 'learning_rate': ['constant', 'invscaling', 'adaptive'], 'hidden_layer_sizes': [(70, 20, 10), (40, 20, 10), (90, 20, 10)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/Users/nehayadav/anaconda2/envs/theano/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:565: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(70, 20, 10), random_state=1)\n",
    "print(\"Training: \")\n",
    "#print(clf)\n",
    "t0 = time()\n",
    "param_grid = {'hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "              'activation' :['logistic', 'tanh', 'relu'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                'alpha':[ 0.0001, 0.001, 0.01]\n",
    "clf = GridSearchCV(MLPClassifier(), param_grid)\n",
    "print(clf)\n",
    "X_train = SelectKBest(chi2, k=2).fit_transform(X_train, y_train)\n",
    "X_test = SelectKBest(chi2, k=2).fit_transform(X_test, y_test)\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)\n",
    "t0 = time()\n",
    "pred = clf.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', MLPClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__hidden_layer_sizes': [(70, 20, 10),(40, 20, 10),(90, 20, 10)],\n",
    "    'clf__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'clf__solver':['lbfgs', 'sgd', 'adam'],\n",
    "    'clf__alpha':[ 0.0001, 0.001, 0.001],\n",
    "    'clf__learning_rate':['constant', 'invscaling', 'adaptive'],\n",
    "    'kbest__k':(1,2),\n",
    "    'kbest__score_func':(f_regression,chi2)\n",
    "}\n",
    "MLPModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "MLPModel.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % MLPModel.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = MLPModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = MLPModel.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "clf1 = LogisticRegression()\n",
    "clf2 = KNeighborsClassifier()\n",
    "clf3 = MLPClassifier()\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3)], voting='hard')\n",
    "print(\"Training: \")\n",
    "print(eclf1)\n",
    "t0 = time()\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "train_time = time() - t0\n",
    "print(\"train time: %0.3fs\" % train_time)\n",
    "t0 = time()\n",
    "pred = eclf1.predict(X_test)\n",
    "test_time = time() - t0\n",
    "print(\"test time:  %0.3fs\" % test_time)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, pred)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, pred, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, pred, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['rfe', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.001, 0.0001, 0.01),\n",
      " 'clf__kernel': ('linear', 'rbf', 'sigmoid', 'poly')}\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 43.849s\n",
      "\n",
      "Best score: 0.505\n",
      "Best parameters set:\n",
      "\tclf__C: 0.001\n",
      "\tclf__kernel: 'linear'\n",
      "Calculated Accuracy is 0.542339696525\n",
      "Precision Score is 0.294132346427\n",
      "Recall Score is 0.542339696525\n",
      "F1 Score is 0.381410589495\n",
      "confusion matrix:\n",
      "[[134 404   6]\n",
      " [170 926  12]\n",
      " [ 72 312   7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', SVC()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__kernel':('linear','rbf','sigmoid','poly'),\n",
    "    'clf__C': (0.001,0.0001,0.01)\n",
    "}\n",
    "SVC_clf = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "SVC_clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % SVC_clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = SVC_clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = SVC_clf.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))\n",
    "print(\"confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['clf']\n",
      "parameters:\n",
      "{'clf__algorithm': ('auto', 'ball_tree', 'kd_tree', 'brute'),\n",
      " 'clf__n_neighbors': (3, 5, 10, 15),\n",
      " 'clf__weights': ('uniform', 'distance')}\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    5.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 11.343s\n",
      "\n",
      "Best score: 0.471\n",
      "Best parameters set:\n",
      "\tclf__algorithm: 'auto'\n",
      "\tclf__n_neighbors: 15\n",
      "\tclf__weights: 'uniform'\n",
      "Calculated Accuracy is 0.493392070485\n",
      "Precision Score is 0.45301706218\n",
      "Recall Score is 0.493392070485\n",
      "F1 Score is 0.449311337433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  96 out of  96 | elapsed:   11.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('rfe', RFECV(estimator=SVC(kernel=\"linear\"),scoring='accuracy',cv=StratifiedKFold(2),step=1)),\n",
    "    ('clf', KNeighborsClassifier()),\n",
    "])\n",
    "parameters = {\n",
    "    'clf__n_neighbors':(3,5,10,15),\n",
    "    'clf__weights':('uniform','distance'),\n",
    "    'clf__algorithm':('auto', 'ball_tree', 'kd_tree', 'brute')\n",
    "}\n",
    "KNNModel = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "KNNModel.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % KNNModel.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = KNNModel.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "predicted = KNNModel.predict(X_test)\n",
    "print(\"Calculated Accuracy is {}\".format(metrics.accuracy_score(y_test, predicted)))\n",
    "print(\"Precision Score is {}\".format(metrics.precision_score(y_test, predicted, average='weighted')))\n",
    "print(\"Recall Score is {}\".format(metrics.recall_score(y_test, predicted, average='weighted')))\n",
    "print(\"F1 Score is {}\".format(metrics.f1_score(y_test, predicted, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
